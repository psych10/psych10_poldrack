---
title: 'Session 8: Data wrangling'
output:
  html_document:
    df_print: paged
---

The goal of this exercise is to learn how to read data into R and get them ready for visualization and analysis.  We will use a set of tools known as the "tidyverse"; in particular, we will teach you about a set of commands that come from the "dplyr" package.

We will use as an example an analysis of whether attitudes about statistics are different between the different student year groups in the class.  

```{r echo=FALSE,message=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(stringr)
library(assertthat)
```


### Statistics attitude data from course survey

These data were collected using the Attitudes Towards Statistics (ATS) scale (from https://www.stat.auckland.ac.nz/~iase/cblumberg/wise2.pdf).

The 29-item ATS has two subscales. The Attitudes Toward Field subscale consists of the following 20 items, with reverse-keyed items indicated by an “(R)”:
1, 3, 5, 6(R), 9, 10(R), 11, 13, 14(R), 16(R), 17, 19, 20(R), 21, 22, 23, 24, 26, 28(R), 29

The Attitudes Toward Course subscale consists of the following 9 items:
2(R), 4(R), 7(R), 8, 12(R), 15(R), 18(R), 25(R), 27(R)

For our purposes, we will just combine all 29 items together, rather than separating them into these subscales.

Let's load the data from the file. First, have a look at the data in the file, to see what separates the different values.  In this case, we see that it is separated by commas, which is known as a "comma-separated value" or CSV file.  We can read this using the read.csv() function.

Note: I have removed the data from the two graduate students in the class and the one 5+ year student, since those would be too easily identifiable.

```{r}
attitudeData=read.csv('https://psych10.github.io/data/Session08_DataWrangling/statsAttitude.txt')
head(attitudeData)
dim(attitudeData)
```

Right now the variable names are somewhat unwieldy, since they include the entire name of the item; this is how Google Forms stores the data.  Let's change the variable names to be somewhat more readable.  We will change the names to "statt<X>" where <X> is replaced with the question number.  We can create these names using the paste0() function.  This function takes a string along with a set of numbers, and creates a vector that combines the string with the number.



```{r}
# The first column is the year
origNames=names(attitudeData)
newNames=c('Year')

# the rest of the columns are for the 29 questions in the statistics attitude survey. 

nQuestions=29

questionNames=paste0('statt',1:nQuestions)
questionNames

newNames = c(newNames,questionNames)

names(attitudeData)=newNames

```

The next thing we need to do is to create an ID for each individual. To do this, we will use the mutate() function from dpylr.  mutate() creates new variables based on the values of existing variables in a data frame.  In this case, we will simply take the row names for each individual, which are numbers from 1 to N, and turn them into a variable in the data frame.

You will also notice something we haven't discussed before: %>%.  This is called a "pipe", which is commonly used within the tidyverse; you can read more [here](http://magrittr.tidyverse.org/). A pipe takes the output from one command and feeds it as input to th next command. In this case, simply writing the name of the data frame (attitudeData) causes it to be input to the mutate() command following the pipe, and the output from the entire operation is stored back in the attitudeData data frame.

The benefit of pipes will become apparent later when we want to start stringing together multiple functions into a single command.


```{r}
# let's add a participant ID so that we will be able to identify them later
attitudeData = attitudeData %>% 
  mutate(ID=row.names(attitudeData))

head(attitudeData)

```

If you look closely at the data, you can see that some of the participants have some missing responses.  We can count them up for each individual and create a new variable to store this using mutate().

We can also create a table showing how many participants have a partiuclar number of NA values.  Here we use two additional commands that you haven't seen yet. The group_by() function tells other functions to do their analyses while breaking the data into groups based on one of the variables.  Here we are going to want to summarize the number of people with each possible number of NAs, so we will group responses by the numNA variable that we are creating in the first command here.  

The summarize() function creates a summary of the data, with the new variables based on the data being fed in.  In this case, we just want to count up the number of subjects in each group, which we can do using the special n() function from dpylr. 


```{r}
# compute the number of NAs for each participant
attitudeData = attitudeData %>% mutate(numNA=rowSums(is.na(.[2:30])))

# present a table with counts of the number of missing responses
attitudeData %>% group_by(numNA) %>% summarise(n=n())

```

We can see from the table that there are two participants who are missing responses for all 29 questions.  Let's find those, using the filter() command from dplyr.  filter() returns the subset of rows from a data frame that match a particular test - in this case, whether numNA is 29.

```{r}

allNA = filter(attitudeData,numNA>1)
allNA
```


There are fancy techniques for trying to guess the value of missing data (known as "imputation") but since the number of participants with missing values is small, let's just drop those participants from the list. We can do this using the drop_na() function from the tidyr package, another package that provides tools for cleaning data.  We will also remove the numNA variable, since we don't need it anymore (since none of the subjects have NA values anymore). We do this using the select() function from dplyr, which selects or removes columns from a data frame.  By putting a minus sign in front of numNA, we are telling it to remove that column.

select() and filter() are very similar - select() works on columns (i.e. variables) and filter() works on rows (i.e. observations).


```{r}
# this is equivalent to drop_na(attitudeData)
attitudeDataNoNA = attitudeData %>% 
  drop_na() %>% select(-numNA)

dim(attitudeDataNoNA)
```

Now we have a fairly well cleaned up dataset, but it's still missing something...


#### Tidy data
Right now we see that each of the different items is stored in a different column.  This violates the principles of ["tidy data"](http://r4ds.had.co.nz/tidy-data.html), which state the following:

- Each variable must have its own column.
- Each observation must have its own row.
- Each value must have its own cell.

This is shown graphically the following figure (from Hadley Wickham, developer of the "tidyverse"):

![Following three rules makes a dataset tidy: variables are in columns, observations are in rows, and values are in cells..](http://r4ds.had.co.nz/images/tidy-1.png)

In our case, each observation is a response, and the variables are the student's year and the response to each question.  This means that we need to create a new dataset, with each row representing a single response.  It will have four columns:
- Year
- ID
- Question
- ResponseRaw (for the raw response, before recoding)

Thus, we want to take the dataset from being "wide" to being "long".  We can do this using the gather() function from the tidyr package.  gather() takes a number of variables and recodes them into two variables: one that contains the value, and another called the key that tells us which column the data came from.  In this case we want it to reshape the data so that each response is on a separate line and the key column tells us which question it represents.  We put minus signs in front of the variables that we do not want to be included in the gather operation - that is, we will keep those as regular variables that will remain in the data frame.

```{r}
attitudeDataTidy = attitudeDataNoNA %>% 
  gather(key=Question,
         value=ResponseRaw,
         -Year, -ID)

head(attitudeDataTidy)
```

OK, now our data are in proper tidy form. ggplot knows how to work with these data, so now it's easy to show a histogram of raw responses.

```{r}
ggplot(attitudeDataTidy,aes(ResponseRaw,..density..)) +
  geom_histogram(binwidth=0.5)
```

This looks like responses are all over the place - but remember from above that some of the items require recoding.  The raw responses were on the 1-7 scale; for the reverse coded itemns, we need to reverse them by subtracting the raw score from 8 (such that 7 becomes 1 and 1 becomes 7).  To do this, we first need to create a column that contains the question numbers. For this we again use the mutate() function, which creates new variables based on the existing variables.  Because we need numbers for the questions, we need to remove the "statt" from their names, which we do using the str_replace() function.

```{r}
# start by filling in the new Response variable with the Raw responses
# then we will flip the relevant ones
# 
attitudeDataTidy = attitudeDataTidy %>%
  mutate(Qnum=as.integer(str_replace(Question,'statt','')))

```

Then we reverse the responses for those items that are in our list of reverse-scored items. We do this using the %in% operator, which tests whether a vector contains a specific value.

```{r}
reverse_score_attitude=c(6,10,14,16,20,28,2,4,7,12,15,18,25,27)

attitudeDataTidy = attitudeDataTidy %>% mutate(Response=ifelse(Qnum %in% reverse_score_attitude,
                                                               8-ResponseRaw,ResponseRaw))

#attitudeDataTidy$Response[attitudeDataTidy$Qnum %in% reverse_score_attitude] = 8 - attitudeDataTidy$ResponseRaw[attitudeDataTidy$Qnum %in% reverse_score_attitude]  

```


Whenever we do an operation like this, it's good to check that it actually worked correctly.  We can do that by identifying all of the question numbers where the raw response is different from the final response, and make sure that they match the set of items that we meant to change.  It's easy to make mistakes in coding, which is why it's important to check your work as well as you can.

One thing we can use to help with checking is what is called an "assertion".  This is basically our way of saying "X should be true, and if it's not, please let me know!".  If the argument to the assertion is false, then it will raise an error in R.

Let's start with an easy version of this - let's make sure that there are no responses outside of the 1-7 scale that we expect, and make sure that no one specified a year outside of the 1-4 range.  (We know these are true, but this shows how we could confirm it if we weren't sure.)

```{r}

assert_that(all(attitudeDataTidy$Response %in% c(1:7)))
assert_that(all(attitudeDataTidy$Year %in% c(1:4)))

```

Now let's try the more complex example, where we check that the question numbers for reversed items are correct. Here we again use the filter() function to select only a subset of cases; in this example we are filtering for items where the raw response is different from the response, which means that its value has been reversed.  Then we make sure that its question number is part of the list of questions that should have been reversed.

```{r}
reversedItemsDf=attitudeDataTidy %>% 
  filter(Response != ResponseRaw) 

assert_that(all(reversedItemsDf$Qnum %in% reverse_score_attitude))
```

Now our data are finally ready to analyze.  First, let's look at the mean overall response across all items.

```{r}
ggplot(attitudeDataTidy,aes(Response,..density..)) +
  geom_histogram(binwidth=0.5)
```

Now that's not so bad - most people respond fairly positively overall.

We can also collapse these by participant, to see what the distribution of overall attitudes looks like across people.  To collapse the results for each participant we will simply sum their responses across all items.

We once again use the group_by() and summarize() functions to summarize the data.

```{r}
participantSummary=attitudeDataTidy %>% 
  group_by(ID) %>%
  summarize(meanResponse=mean(Response), 
            year=unique(Year))

ggplot(participantSummary,aes(meanResponse)) +
  geom_histogram(bins=20)

```

Now we can also separate these out by year.

```{r}
participantSummaryByYear=attitudeDataTidy %>% 
  group_by(Year) %>%
  summarize(meanResponse=mean(Response),
            sd=sd(Response),n=n()/nQuestions)

ggplot(participantSummaryByYear,aes(x=Year,y=meanResponse)) +
  geom_line(stat="identity")
```

